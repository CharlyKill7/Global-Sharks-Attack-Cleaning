{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18af4edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # me muestre todas las columnas\n",
    "pd.set_option('display.max_colwidth', 100)  #me muestre más caracteres por columna.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a3eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('attacks.csv', encoding= \"ISO-8859-1\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9ea47b",
   "metadata": {},
   "source": [
    "# Glosario de columnas y tipos iniciales\n",
    "\n",
    "0. Case Number: La fecha coincide con el case number. OBJETC\n",
    "1. Date: La fecha del ataque. OBJECT\n",
    "2. Year: El año del ataque. FLOAT64\n",
    "3. Type: Tipo de ataque (provocado, no provocado, desastre marino, etc). OBJECT\n",
    "4. Country: País del ataque. OBJECT\n",
    "5. Area: Area del país. OBJECT\n",
    "6. Location: Localización concreta dentro del area. OBJECT\n",
    "7. Activity: La actividad que se estaba realizando durante el ataque. OBJECT\n",
    "8. Name: Nombre de la víctima. OBJECT\n",
    "9. Sex: Género de la víctima. OBJECT\n",
    "10. Age: Edad de la víctima. OBJECT\n",
    "11. Injury: Tipo de lesión provocada. OBJECT\n",
    "12. Fatal: Muerte o no de la victima. OBJECT\n",
    "13. Time: Hora del ataque. OBJECT\n",
    "14. Species: Especie del tiburón del ataque. OBJECT\n",
    "15. Investigator or Source: Investigador del ataque + organización a la que pertenece. OBJECT\n",
    "16. pdf: Imagino que un pdf del informe del ataque por víctima. OBJECT\n",
    "17. href formula: Enlace al informe en pdf del apartado anterior. OBJECT\n",
    "18. href: Parece una columna con lo mismo que lo anterior pero tiene menos filas. OBJECT\n",
    "19. Case Number.1: Columna igual que Case Number pero con dos filas menos. OBJECT\n",
    "20. Case Number.2: Columna igual que Case Number pero con una fila menos. OBJECT\n",
    "21. Original Order: Parece un id del caso, a priori mayor cuanto más reciente. FLOAT64\n",
    "22. Unnamed: 22: No sé qué significa, todo NaNs salvo el 1478 \"stopped here\". OBJECT\n",
    "23. Unnamed: 23: No sé qué significa, todo NaNs salvo el 4415 \"Teramo\" y el 5840 \"change filename\". OBJECT\n",
    "\n",
    "- Dimensión inicial del DataFrame: (25723, 24)\n",
    "\n",
    "# Restricciones:\n",
    "- No se pueden eliminar columnas.\n",
    "- Deben quedar al menos 1500 filas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12aed68a",
   "metadata": {},
   "source": [
    "# Primeras consideraciones\n",
    "\n",
    "- Como no podemos eliminar columnas, el % de nulos por columna no es tan relevante.\n",
    "- Sí podemos quitar todas las filas en las que todos los valores sean nulos. \n",
    "- Sí podemos quitar todas las filas duplicadas.\n",
    "- Arreglar los nombres de las columnas para trabajar mejor con ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7002b237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25723 entries, 0 to 25722\n",
      "Data columns (total 24 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Case Number             8702 non-null   object \n",
      " 1   Date                    6302 non-null   object \n",
      " 2   Year                    6300 non-null   float64\n",
      " 3   Type                    6298 non-null   object \n",
      " 4   Country                 6252 non-null   object \n",
      " 5   Area                    5847 non-null   object \n",
      " 6   Location                5762 non-null   object \n",
      " 7   Activity                5758 non-null   object \n",
      " 8   Name                    6092 non-null   object \n",
      " 9   Sex                     5737 non-null   object \n",
      " 10  Age                     3471 non-null   object \n",
      " 11  Injury                  6274 non-null   object \n",
      " 12  Fatal (Y/N)             5763 non-null   object \n",
      " 13  Time                    2948 non-null   object \n",
      " 14  Species                 3464 non-null   object \n",
      " 15  Investigator or Source  6285 non-null   object \n",
      " 16  pdf                     6302 non-null   object \n",
      " 17  href formula            6301 non-null   object \n",
      " 18  href                    6302 non-null   object \n",
      " 19  Case Number.1           6302 non-null   object \n",
      " 20  Case Number.2           6302 non-null   object \n",
      " 21  original order          6309 non-null   float64\n",
      " 22  Unnamed: 22             1 non-null      object \n",
      " 23  Unnamed: 23             2 non-null      object \n",
      "dtypes: float64(2), object(22)\n",
      "memory usage: 22.8 MB\n"
     ]
    }
   ],
   "source": [
    "data.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "213756c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25723, 24)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ori_shape = data.shape\n",
    "\n",
    "data_ori = data.copy()\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab833e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c7d9961",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bc84715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6311, 24), (25723, 24))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, data_ori.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31353e64",
   "metadata": {},
   "source": [
    "Tras hacerlo, las dimensiones pasan a ser: (6311, 24)\n",
    "\n",
    "Ahora voy a cambiar los nombres de las columnas para homogeneizarlas, por si acaso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46787819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
       "       'Species ', 'Investigator or Source', 'pdf', 'href formula', 'href',\n",
       "       'Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22',\n",
       "       'Unnamed: 23'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce160734",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [e.replace(' ', '_') for e in data.columns]\n",
    "\n",
    "data.columns = [e.replace('.', '_') for e in data.columns]\n",
    "\n",
    "data.columns = [e.replace(':', '') for e in data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b54749",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Species_': 'Species', 'Sex_': 'Sex', 'Fatal_(Y/N)': 'Fatal', 'Investigator_or_Source': 'Source'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493226f6",
   "metadata": {},
   "source": [
    "A continuación voy a eliminar las filas que tengan más de un 50% de valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98e5a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = data.isnull()                                      # Me devuelve una mascara booleana de toda la tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2053d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values_count = mask.T.sum()                          # Me devuelve el nº de NaN que hay por fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e233f4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_por_linea_100 = (null_values_count/len(data.T)) *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cb08304",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2 = nan_por_linea_100 > 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69a5b74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''La línea de código data = data[~mask2] es utilizada para filtrar las filas de un DataFrame en base \n",
    "a una máscara booleana.\n",
    "La expresión ~mask2 invertirá los valores booleanos de la máscara, es decir, todos los valores True se \n",
    "convertirán en False y viceversa. Con esto, las filas que antes eran True (más del 50% de valores nulos) \n",
    "ahora serán False y serán eliminadas.\n",
    "'''\n",
    "\n",
    "data = data[~mask2]            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d5f359",
   "metadata": {},
   "source": [
    "Las dimensiones del DataFrame pasan a ser: (6302, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afc11063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6302, 24)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca821c",
   "metadata": {},
   "source": [
    "En mi exploración me ha parecido que la columna original_order está ordenada de forma descendente. Procedo a comprobarlo y, de ser así, daré la columna por \"buena\". Tal vez más adelante, cuando haya terminado de eliminar filas, resetee esta columna para que vaya desde el 1 hasta el último caso y la renombre como una especie de número de caso, de id. De ser posible la convertiré también a integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2928ef5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(data['original_order'].is_monotonic_decreasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "466f86ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['original_order'] = data['original_order'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5139453f",
   "metadata": {},
   "source": [
    "A continuación, centro mi atención en la columna 'Year', con el fin de tener ordenadas las filas al menos por año. Analizando el final del dataframe con .iloc, me doy cuenta de que los últimos años no tienen datos consistentes en la columna 'Year' a partir del índice 6173 en adelante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1825e6af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6172    1554.0\n",
       "6173    1543.0\n",
       "6174     500.0\n",
       "6175      77.0\n",
       "6176       5.0\n",
       "         ...  \n",
       "6297       0.0\n",
       "6298       0.0\n",
       "6299       0.0\n",
       "6300       0.0\n",
       "6301       0.0\n",
       "Name: Year, Length: 130, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Year'].iloc[6172:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16814b",
   "metadata": {},
   "source": [
    "Por tanto, es posible que decida eliminar las filas finales, pero primero quiero tener claro que el resto de años sí están ordenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b272fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Year'].iloc[:6173].is_monotonic_decreasing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32d40c8",
   "metadata": {},
   "source": [
    "No están ordenados, así que procedo a ordenar el dataframe según la columna. Después compruebo si ahora sí, salvo las últimas filas, está ordenados consistentemente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4272695",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(by='Year',ascending=False)\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be967c5",
   "metadata": {},
   "source": [
    "Tras ordenarlo, parece que el nuevo indice a partir del cual empiezan los años consistentes es el 6171, así que a partir de él miro si están ordenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24dd5f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Year'].loc[:6171].is_monotonic_decreasing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5f9af8",
   "metadata": {},
   "source": [
    "En efecto, ya tengo la el dataframe ordenado por años, a falta de eliminar las últimas filas, lo cual procedo a realizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cea73f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[:6171]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36340baa",
   "metadata": {},
   "source": [
    "Voy a aprovechar para convertir los valores de la columna a enteros ya que los años son siempre enteros y así el Dataframe ocupará menos espacio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "152cc8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Year'] = data['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f060b7d3",
   "metadata": {},
   "source": [
    "A continuación y tras analizar la columna 'Date', voy a intentar quedarme con el mes (ya tengo una columna con el año) en formato 1-12, con el fin de que ocupe menos y pueda manejar sus datos como númericos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4537ccf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierto la columna a formato fecha con pd.to_datetime.\n",
    "# El parámetro errors='coerce' sirve para que los que no puedan convertirse pasen a ser NaN.\n",
    "# Uso dt.month para asignar el valor númerico del mes a la propia columna 'Date'.\n",
    "\n",
    "data['Date'] = pd.to_datetime(data['Date'], errors='coerce').dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed5606d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    5458\n",
       "True      714\n",
       "Name: Date, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Date'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e754bdd7",
   "metadata": {},
   "source": [
    "Ahora voy a rellenar los NaN de la columna con el mes más repetido (moda), ya que la proporción de NaN me parece bastante baja en relación a los meses que sí tengo. Doy por hecho que si hay más ataques en enero en general, el valor menos adulterado será poner 1.0 (enero). Usar la media me daría meses con decimales, y rellenar con unknown o 0 me impediría trabajar correctamente con la columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ed16705",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'].fillna(data['Date'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd21d5c6",
   "metadata": {},
   "source": [
    "Una vez hecho esto, voy a cambiar el nombre de la columna por 'Month' y a convertir la columna a integers, ya que los meses son siempre enteros y así el Dataframe ocupará menos espacio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4270bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Date': 'Month'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9ccf0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Month'] = data['Month'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c91befa",
   "metadata": {},
   "source": [
    "Lo siguiente que voy a intentar es, ya que tengo mes y año, asignar a la columna 'Case_Number' el día del mes en que ocurrió el ataque. Tras analizar la columna, lo primero que voy a hacer es quitar los caracteres alfabéticos (letras) de la string, con el fin de dejar solo las fechas y extraer el día como he hecho con el mes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e1b7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Case_Number'] = data['Case_Number'].str.replace(r'[a-zA-Z]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd70ecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Case_Number'] = pd.to_datetime(data['Case_Number'], errors='coerce').dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b96913a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    5417\n",
       "True      755\n",
       "Name: Case_Number, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Case_Number'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3383e5",
   "metadata": {},
   "source": [
    "En este caso, para los días del mes vacíos (NaN), voy a generar una serie de números aleatorios para rellenar dichos valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5086bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Con el código siguiente, creo una lista vacía y lo que hago es iterar por todas las filas del DF. Si la columna \n",
    "'Case_Number' contiene un NaN, entonces añade a la lista un entero aleatorio entre 1 y 28 (días de mes) y, en\n",
    "caso contrario, añade el valor actual a la lista. Finalmente relleno toda la columna con la lista obtenida.\n",
    "entonces \n",
    "'''\n",
    "\n",
    "import random\n",
    "\n",
    "days = []\n",
    "\n",
    "for i in data.index:\n",
    "    \n",
    "    if pd.isnull(data['Case_Number'].iloc[i]):\n",
    "        \n",
    "        days.append(random.randint(1,28))\n",
    "    else:\n",
    "        \n",
    "        days.append(data['Case_Number'].iloc[i])\n",
    "        \n",
    "data['Case_Number'] = days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e4b95",
   "metadata": {},
   "source": [
    "Ya tengo mi columna exactamente como la quiero, así que procedo a cambiarle el nombre y el tipo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23b8c417",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Case_Number': 'Day'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cb3efa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Day'] = data['Day'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e2e862",
   "metadata": {},
   "source": [
    "Ahora voy a por la columna 'Type'. Primero analizo la distribución de sus valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a38cf38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unprovoked      4483\n",
       "Provoked         567\n",
       "Invalid          544\n",
       "Sea Disaster     233\n",
       "Boating          203\n",
       "Boat             135\n",
       "Questionable       2\n",
       "Boatomg            1\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2278e6",
   "metadata": {},
   "source": [
    "Primero voy a unificar 'Boating', 'Boat' y 'Boatomg' como 'Boating'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d398d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Type'] = data['Type'].replace({'Boatomg': 'Boat'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5dc1778a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Type'] = data['Type'].replace({'Boat': 'Boating'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d01c7",
   "metadata": {},
   "source": [
    "A continuación, voy a analizar los 'Questionable' con el fin de tomar una decisión sobre ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f23f674a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href_formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case_Number_1</th>\n",
       "      <th>Case_Number_2</th>\n",
       "      <th>original_order</th>\n",
       "      <th>Unnamed_22</th>\n",
       "      <th>Unnamed_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>Questionable</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Lennox Head</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Matthew Lee</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No injury</td>\n",
       "      <td>N</td>\n",
       "      <td>07h00</td>\n",
       "      <td>Questionable</td>\n",
       "      <td>B. Myatt, GSAF</td>\n",
       "      <td>2018.04.25.b-Lee.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_directory/2018.04.25.b-Lee.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_directory/2018.04.25.b-Lee.pdf</td>\n",
       "      <td>2018.04.25.b</td>\n",
       "      <td>2018.04.25.b</td>\n",
       "      <td>6283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>Questionable</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Sharpes Beach, Ballina</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No injury, surfboard damaged</td>\n",
       "      <td>N</td>\n",
       "      <td>10h30</td>\n",
       "      <td>Shark involvement not confirmed</td>\n",
       "      <td>B. Myatt, GSAF</td>\n",
       "      <td>2018.05.09-SharpesBeach.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_directory/2018.05.09-SharpesBeach.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_directory/2018.05.09-SharpesBeach.pdf</td>\n",
       "      <td>2018.05.09</td>\n",
       "      <td>2018.05.09</td>\n",
       "      <td>6287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Day  Month  Year          Type    Country             Area  \\\n",
       "47   25      4  2018  Questionable  AUSTRALIA  New South Wales   \n",
       "51    9      5  2018  Questionable  AUSTRALIA  New South Wales   \n",
       "\n",
       "                  Location Activity         Name Sex  Age  \\\n",
       "47             Lennox Head  Surfing  Matthew Lee   M  NaN   \n",
       "51  Sharpes Beach, Ballina  Surfing         male   M  NaN   \n",
       "\n",
       "                          Injury Fatal   Time  \\\n",
       "47                     No injury     N  07h00   \n",
       "51  No injury, surfboard damaged     N  10h30   \n",
       "\n",
       "                            Species          Source  \\\n",
       "47                     Questionable  B. Myatt, GSAF   \n",
       "51  Shark involvement not confirmed  B. Myatt, GSAF   \n",
       "\n",
       "                            pdf  \\\n",
       "47         2018.04.25.b-Lee.pdf   \n",
       "51  2018.05.09-SharpesBeach.pdf   \n",
       "\n",
       "                                                                         href_formula  \\\n",
       "47         http://sharkattackfile.net/spreadsheets/pdf_directory/2018.04.25.b-Lee.pdf   \n",
       "51  http://sharkattackfile.net/spreadsheets/pdf_directory/2018.05.09-SharpesBeach.pdf   \n",
       "\n",
       "                                                                                 href  \\\n",
       "47         http://sharkattackfile.net/spreadsheets/pdf_directory/2018.04.25.b-Lee.pdf   \n",
       "51  http://sharkattackfile.net/spreadsheets/pdf_directory/2018.05.09-SharpesBeach.pdf   \n",
       "\n",
       "   Case_Number_1 Case_Number_2  original_order Unnamed_22 Unnamed_23  \n",
       "47  2018.04.25.b  2018.04.25.b            6283        NaN        NaN  \n",
       "51    2018.05.09    2018.05.09            6287        NaN        NaN  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['Type'] == 'Questionable']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e3bf5e",
   "metadata": {},
   "source": [
    "En la columna 'Species' se questiona el hecho de que un tiburón estuviera involucrado, y en ese caso no tendría sentido conservar estas líneas con sus datos. Además, la columna 'Injury' indica que no hubo lesiones, lo que refuerza la hipótesis. Por tanto, procedo a eliminar esas filas y ajustar el índice.\n",
    "\n",
    "Nota: la columna 'original_order' perderá entonces su orden consecutivo, por lo que seguramente tendré que ajustarla después."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f7ffa4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data[data['Type'] == 'Questionable'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9096e4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b55319",
   "metadata": {},
   "source": [
    "Ahora la columna 'Type' tiene solo cinco valores únicos, los cuales decido conservar. Procedo a remplazar los NaN por 'Invalid' y termino con ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2216d2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Type'].fillna(value='Invalid', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce5dc9",
   "metadata": {},
   "source": [
    "A continuación, saco los valores únicos de la columna 'Country', con el fin de unificar o borrar en caso de necesidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad81795e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['USA', 'AUSTRALIA', 'BAHAMAS', 'BRAZIL', 'NEW CALEDONIA',\n",
       "       'SOUTH AFRICA', 'ECUADOR', 'THAILAND', 'ENGLAND', 'MEXICO',\n",
       "       'MALDIVES', 'COSTA RICA', 'UNITED ARAB EMIRATES',\n",
       "       'ST HELENA, British overseas territory', 'REUNION', 'NEW ZEALAND',\n",
       "       'UNITED KINGDOM', 'FRENCH POLYNESIA', 'SPAIN', 'COMOROS',\n",
       "       'INDONESIA', 'PHILIPPINES', 'MAURITIUS', 'LIBYA', nan, 'CUBA',\n",
       "       'SAMOA', 'MALAYSIA', 'EGYPT', 'SOLOMON ISLANDS', 'JAPAN',\n",
       "       'COLUMBIA', 'CAPE VERDE', 'CAYMAN ISLANDS', 'DOMINICAN REPUBLIC',\n",
       "       'Fiji', 'CHINA', 'PUERTO RICO', 'ATLANTIC OCEAN', 'ITALY',\n",
       "       'MOZAMBIQUE', 'ARUBA', 'FIJI', 'FRANCE', 'ST. MARTIN',\n",
       "       'TRINIDAD & TOBAGO', 'PAPUA NEW GUINEA', 'GREECE',\n",
       "       'PALESTINIAN TERRITORIES', 'JAMAICA', 'TAIWAN', 'DIEGO GARCIA',\n",
       "       'BELIZE', 'SEYCHELLES', 'GUAM', 'ISRAEL', 'KIRIBATI', 'CHILE',\n",
       "       'SAUDI ARABIA', 'CROATIA', 'NIGERIA', 'TONGA', 'CANADA',\n",
       "       'SCOTLAND', 'TURKS & CAICOS', 'UNITED ARAB EMIRATES (UAE)',\n",
       "       'ANTIGUA', 'RUSSIA', 'KENYA', 'VIETNAM', 'MADAGASCAR', 'AZORES',\n",
       "       'MALTA', 'SOUTH KOREA', 'PANAMA', 'NEVIS', 'SOMALIA', 'SENEGAL',\n",
       "       'NORWAY', 'YEMEN', 'BRITISH VIRGIN ISLANDS', 'Sierra Leone',\n",
       "       'GULF OF ADEN', 'VANUATU', 'MEXICO ', 'VENEZUELA', 'HONDURAS',\n",
       "       'LIBERIA', 'GRAND CAYMAN', 'ST. MAARTIN', 'Seychelles', ' TONGA',\n",
       "       'URUGUAY', 'SRI LANKA', 'INDIA', 'MICRONESIA', 'CARIBBEAN SEA',\n",
       "       'TANZANIA', 'OKINAWA', 'MARSHALL ISLANDS', 'EGYPT / ISRAEL',\n",
       "       'HONG KONG', 'NORTHERN ARABIAN SEA', 'ANGOLA', 'EL SALVADOR',\n",
       "       'MONTENEGRO', 'IRAN', 'TUNISIA', 'BERMUDA', 'NAMIBIA',\n",
       "       'NORTH ATLANTIC OCEAN', 'PORTUGAL', 'SOUTH CHINA SEA',\n",
       "       'BANGLADESH', 'PALAU', 'WESTERN SAMOA', 'PACIFIC OCEAN ', 'TURKEY',\n",
       "       'BRITISH ISLES', 'IRAQ', 'GRENADA', 'SUDAN', 'SINGAPORE',\n",
       "       'NEW BRITAIN', 'NEW GUINEA', 'RED SEA', 'JOHNSTON ISLAND',\n",
       "       'SOUTH PACIFIC OCEAN', 'FEDERATED STATES OF MICRONESIA',\n",
       "       'NORTH PACIFIC OCEAN', 'SOUTH ATLANTIC OCEAN',\n",
       "       'BRITISH WEST INDIES', 'ADMIRALTY ISLANDS', 'MID ATLANTIC OCEAN',\n",
       "       'PERSIAN GULF', 'NICARAGUA ', 'RED SEA / INDIAN OCEAN',\n",
       "       'PACIFIC OCEAN', 'NORTH SEA', 'MALDIVE ISLANDS', 'AMERICAN SAMOA',\n",
       "       'ANDAMAN / NICOBAR ISLANDAS', 'GABON', 'MAYOTTE',\n",
       "       'NORTH ATLANTIC OCEAN ', 'SUDAN?', 'ARGENTINA', 'MARTINIQUE',\n",
       "       'THE BALKANS', 'INDIAN OCEAN', 'NETHERLANDS ANTILLES', 'GUATEMALA',\n",
       "       'NORTHERN MARIANA ISLANDS', 'JAVA', 'IRAN / IRAQ', 'NICARAGUA',\n",
       "       'SIERRA LEONE', ' PHILIPPINES', 'CENTRAL PACIFIC',\n",
       "       'MID-PACIFC OCEAN', 'SOUTHWEST PACIFIC OCEAN', 'BAY OF BENGAL',\n",
       "       'SOLOMON ISLANDS / VANUATU', 'SLOVENIA', 'CURACAO', 'ICELAND',\n",
       "       'ITALY / CROATIA', 'BARBADOS', 'MONACO', 'GUYANA', 'HAITI',\n",
       "       'SAN DOMINGO', 'IRELAND', 'KUWAIT', 'YEMEN ', 'REUNION ISLAND',\n",
       "       'CRETE', 'FALKLAND ISLANDS', 'CYPRUS', 'EGYPT ', 'WEST INDIES',\n",
       "       'BURMA', 'LEBANON', 'PARAGUAY', 'CEYLON', 'BRITISH NEW GUINEA',\n",
       "       'OCEAN', 'GEORGIA', 'SYRIA', 'TUVALU', 'INDIAN OCEAN?',\n",
       "       'ANDAMAN ISLANDS', 'GUINEA', 'EQUATORIAL GUINEA / CAMEROON',\n",
       "       'COOK ISLANDS', 'TOBAGO', 'PERU', 'AFRICA', 'ALGERIA',\n",
       "       'Coast of AFRICA', 'TASMAN SEA', 'GHANA', 'GREENLAND',\n",
       "       'MEDITERRANEAN SEA', 'SWEDEN', 'ROATAN',\n",
       "       'Between PORTUGAL & INDIA'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Country.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d1f9ec",
   "metadata": {},
   "source": [
    "En el notebook en sucio 'draft' de esta misma carpeta, voy investigando caso por caso con el fin de adecuar 'Country' a lo que realmente corresponda, si es posible. Para ello utilizo la localización si existe, o incluso intento abrir el link con el pdf del suceso. En caso de no descubrirlo, tomaré una decisión para rellenarlo, lo mismo que con los NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "59e06b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Country'] = data['Country'].replace({'Fiji': 'FIJI', 'ST HELENA, British overseas territory': 'UNITED KINGDOM OVERSEAS', 'DIEGO GARCIA': 'UNITED KINGDOM OVERSEAS', 'Sierra Leone': 'SIERRA LEONE', 'Seychelles': 'SEYCHELLES',\n",
    "                                 'EGYPT / ISRAEL': 'EGYPT', 'PACIFIC OCEAN ': 'PACIFIC OCEAN', 'BRITISH ISLES': 'UNITED KINGDOM', 'ENGLAND': 'UNITED KINGDOM', 'ST. MAARTIN': 'ST MARTIN', 'ST. MARTIN': 'ST MARTIN',\n",
    "                                'NORTH ATLANTIC OCEAN ': 'NORTH ATLANTIC OCEAN', 'FEDERATED STATES OF MICRONESIA': 'MICRONESIA', 'BRITISH WEST INDIES': 'UNITED KINGDOM OVERSEAS', 'RED SEA / INDIAN OCEAN': 'RED SEA', 'ANDAMAN / NICOBAR ISLANDAS': 'BAY OF BENGAL',\n",
    "                                 'SUDAN?': 'SUDAN', 'THE BALKANS': 'SLOVENIA', 'IRAN / IRAQ': 'IRAN', ' PHILIPPINES': 'PHILIPPINES', 'SOLOMON ISLANDS / VANUATU': 'VANUATU', 'ITALY / CROATIA': 'CROATIA', 'YEMEN ': 'YEMEN', 'REUNION': 'REUNION ISLAND',\n",
    "                                'EGYPT ': 'EGYPT', 'BRITISH NEW GUINEA': 'UNITED KINGDOM OVERSEAS', 'OCEAN': 'PACIFIC OCEAN', 'INDIAN OCEAN?': 'INDIAN OCEAN', 'EQUATORIAL GUINEA / CAMEROON': 'CAMEROON', 'Coast of AFRICA': 'ATLANTIC OCEAN', 'Between PORTUGAL & INDIA': 'INDIAN OCEAN',\n",
    "                                'TURKS & CAICOS': 'UNITED KINGDOM OVERSEAS', 'TRINIDAD & TOBAGO': 'TOBAGO', 'UNITED ARAB EMIRATES (UAE)': 'UNITED ARAB EMIRATES', 'BRITISH VIRGIN ISLANDS': 'UNITED KINGDOM OVERSEAS', ' TONGA': 'TONGA', 'MEXICO ': 'MEXICO', 'NICARAGUA ': 'NICARAGUA',\n",
    "                                 'MID-PACIFC OCEAN': 'MID PACIFIC OCEAN'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afddd15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Country'].fillna(value='unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75ad4746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Country.isna().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeebd33",
   "metadata": {},
   "source": [
    "Así queda limpia otra columna. Sin embargo, en el análisis caso por caso he descubierto que el índice 6047, 'AFRICA' según la columna 'Country', no tiene prácticamente información, así que procedo a eliminar esta línea y reiniciar el índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47e3f684",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(6047)\n",
    "\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322fd9ed",
   "metadata": {},
   "source": [
    "Las columnas 'Area' y 'Location' contienen demasiados valores únicos como para revisarlos todos. De momento, voy a rellenar con 'unknown' todas aquellas filas que en ambas columnas tengan NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e75fec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "doble_nan = (data.Area.isna() == True) & (data.Location.isna() == True)\n",
    "\n",
    "data.loc[doble_nan, [\"Area\",\"Location\"]] = data.loc[doble_nan, [\"Area\",\"Location\"]].fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72327c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[(data.Area.isna() == True) | (data.Location.isna() == True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969ad0b0",
   "metadata": {},
   "source": [
    "Una vez reemplazados los NaN que coinciden en ambas filas, pretendía ver si con lo uno o con lo otro podía rellenar correctamente el Nan de al lado. Sin embargo, 495 filas parecen ser demasiadas como para ir una a una. No obstante, tras observar unas cuantas decenas de filas, me doy cuenta de que en muchos de los NaN que hay en 'Area' pueden ser porque no existe denominación intermedia entre el país y la localización, como en el caso de las islas. En el caso de 'Location', parece que en muchos casos simplemente no consta el lugar preciso. Como conclusión, y aunque seguro que podría rellenar alguna que otra fila, creo que lo más sensato es rellenar el NaN de una columna con lo que sí viene informado en la otra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd4b4a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Area.fillna(data.Location, inplace=True)\n",
    "data.Location.fillna(data.Area, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3b136b",
   "metadata": {},
   "source": [
    "A continuación voy a investigar los principales valores de la columna Activity con el fin de unificar aquellos en los que proceda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd0bd0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surfing                 968\n",
       "Swimming                853\n",
       "Fishing                 423\n",
       "Spearfishing            332\n",
       "Bathing                 159\n",
       "Wading                  147\n",
       "Diving                  115\n",
       "Standing                 97\n",
       "Snorkeling               88\n",
       "Scuba diving             75\n",
       "Body boarding            61\n",
       "Body surfing             49\n",
       "Swimming                 47\n",
       "Kayaking                 33\n",
       "Fell overboard           32\n",
       "Treading water           32\n",
       "Boogie boarding          29\n",
       "Pearl diving             28\n",
       "Free diving              27\n",
       "Windsurfing              19\n",
       "Walking                  17\n",
       "Boogie Boarding          16\n",
       "Shark fishing            15\n",
       "Floating                 14\n",
       "Fishing                  13\n",
       "Rowing                   12\n",
       "Surf fishing             12\n",
       "Surf-skiing              12\n",
       "Surf skiing              12\n",
       "Canoeing                 12\n",
       "Fishing for sharks       11\n",
       "Kayak Fishing            11\n",
       "Scuba Diving             10\n",
       "Freediving               10\n",
       "Sailing                   9\n",
       "Sitting on surfboard      9\n",
       "Sea disaster              8\n",
       "Paddle boarding           8\n",
       "Diving for trochus        8\n",
       "Fell into the water       8\n",
       "Name: Activity, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Activity.value_counts().head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8beb5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero una máscara booleana que devuelve True si 'urf' está contenido en el valor.\n",
    "\n",
    "mask3 = data['Activity'].str.contains('urf')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e758b0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizo np.where con la mask como primer argumento, para que donde sea True complete con 'Surfing' (2º argumento).\n",
    "# En caso de False, rellena con el valor correspondiente de data['Activity'] (3º argumento).\n",
    "\n",
    "data['Activity'] = np.where(mask3, 'Surfing', data['Activity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57c4fbe",
   "metadata": {},
   "source": [
    "Ahora voy a seguir el mismo procedimiento para intentar unificar el máximo de valores que sea posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4fc01054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surfing                       1781\n",
       "Swimming                       853\n",
       "Fishing                        423\n",
       "Spearfishing                   332\n",
       "Bathing                        159\n",
       "Wading                         147\n",
       "Diving                         115\n",
       "Standing                        97\n",
       "Snorkeling                      88\n",
       "Scuba diving                    75\n",
       "Body boarding                   61\n",
       "Swimming                        47\n",
       "Kayaking                        33\n",
       "Fell overboard                  32\n",
       "Treading water                  32\n",
       "Boogie boarding                 29\n",
       "Pearl diving                    28\n",
       "Free diving                     27\n",
       "Walking                         17\n",
       "Boogie Boarding                 16\n",
       "Shark fishing                   15\n",
       "Floating                        14\n",
       "Fishing                         13\n",
       "Canoeing                        12\n",
       "Rowing                          12\n",
       "Kayak Fishing                   11\n",
       "Fishing for sharks              11\n",
       "Freediving                      10\n",
       "Scuba Diving                    10\n",
       "Sailing                          9\n",
       "Paddle boarding                  8\n",
       "Fell into the water              8\n",
       "Diving for trochus               8\n",
       "Sea disaster                     8\n",
       "Diving for abalone               7\n",
       "Boating                          7\n",
       "Sponge diving                    7\n",
       "Playing                          7\n",
       "Free diving for abalone          7\n",
       "Stand-Up Paddleboarding          6\n",
       "Murder                           6\n",
       "Fishing for mackerel             6\n",
       "Spearfishing on Scuba            6\n",
       "Skindiving                       6\n",
       "Sea Disaster                     6\n",
       "Floating on his back             6\n",
       "Fishing on a boat                5\n",
       "Freedom swimming                 5\n",
       "Paddleskiing                     5\n",
       "Boat                             5\n",
       "Shipwreck                        5\n",
       "Kayaking / Fishing               5\n",
       "Hard hat diving                  5\n",
       "Dangling feet in the water       5\n",
       "Fishing boat                     4\n",
       "Clamming                         4\n",
       "Scuba diving (submerged)         4\n",
       "Freedom Swimming                 4\n",
       "Wade Fishing                     4\n",
       "Spearfishing / free diving       4\n",
       "Name: Activity, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Activity.value_counts().head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "48a5d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Activity'] = np.where(data['Activity'].str.contains('urf'), 'Surfing', data['Activity'])\n",
    "\n",
    "data['Activity'] = np.where(data['Activity'].str.contains('ishin'), 'Fishing', data['Activity'])\n",
    "\n",
    "data['Activity'] = np.where(data['Activity'].str.contains('iving'), 'Diving', data['Activity'])\n",
    "\n",
    "data['Activity'] = np.where(data['Activity'].str.contains('wim'), 'Swimming', data['Activity'])\n",
    "\n",
    "data['Activity'] = np.where(data['Activity'].str.contains('ath'), 'Bathing', data['Activity'])\n",
    "\n",
    "data['Activity'] = np.where(data['Activity'].str.contains('oard'), 'Boarding', data['Activity'])\n",
    "\n",
    "data['Activity'] = np.where(data['Activity'].str.contains('ayak'), 'Boating', data['Activity'])\n",
    "\n",
    "data['Activity'] = np.where(data['Activity'].str.contains('Boat'), 'Boating', data['Activity'])\n",
    "\n",
    "data['Activity'] = np.where(data['Activity'].str.contains('boat'), 'Boating', data['Activity'])\n",
    "\n",
    "data['Activity'] = np.where(data['Activity'].str.contains('Walking'), 'Wading', data['Activity'])\n",
    "\n",
    "data['Activity'] = np.where(data['Activity'].str.contains('Standing'), 'Standing', data['Activity'])\n",
    "\n",
    "data['Activity'] = np.where(data['Activity'].str.contains('loating'), 'Swimming', data['Activity'])\n",
    "\n",
    "data['Activity'] = np.where(data['Activity'].str.contains('Canoe'), 'Boating', data['Activity'])\n",
    "\n",
    "data['Activity'] = np.where(data['Activity'].str.contains('Sail'), 'Boating', data['Activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be4bfbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surfing       1781\n",
       "Fishing       1118\n",
       "Swimming      1114\n",
       "Diving         482\n",
       "Boarding       268\n",
       "Bathing        195\n",
       "Wading         167\n",
       "Boating        150\n",
       "Standing       119\n",
       "Snorkeling      88\n",
       "Name: Activity, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Activity.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e7ff60",
   "metadata": {},
   "source": [
    "El resto de categorías, al ser tan poco representativas como confusas, voy a intentar unificarlas bajo el valor 'unknown'. Empezaré por los valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6164f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Activity'].fillna(value='unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e1dbe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero creo un diccionario con los valores que quiero que se mantengan.\n",
    "\n",
    "excepts = {'Surfing':'Surfing', 'Fishing':'Fishing', 'Swimming':'Swimming', 'Diving':'Diving', 'Boarding':'Boarding', \n",
    "                'Bathing':'Bathing', 'Wading':'Wading', 'Boating':'Boating', 'Standing':'Standing', 'Snorkeling':'Snorkeling'}\n",
    "\n",
    "# Con data['Activity'].isin(excepts) uso otra máscara bool para seleccionar las filas cuyo valor está en excepts.\n",
    "# Virgulilla ~ para negar esa condición, y que así el .loc elija las filas correctas de 'Activity' donde poner 'unknown'.\n",
    "\n",
    "data.loc[~data['Activity'].isin(excepts), 'Activity'] = 'unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf293f84",
   "metadata": {},
   "source": [
    "A continuación analizo la columna 'Name'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f67a4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male             520\n",
       "female            95\n",
       "boy               21\n",
       "2 males           16\n",
       "boat              14\n",
       "child             12\n",
       "sailor            10\n",
       "Anonymous         10\n",
       "a sailor           8\n",
       "girl               6\n",
       "Unidentified       6\n",
       "males              6\n",
       "a soldier          5\n",
       "a native           5\n",
       "fisherman          4\n",
       "2 fishermen        4\n",
       "Unknown            4\n",
       "black male         4\n",
       "a pearl diver      4\n",
       "John Williams      3\n",
       "Name: Name, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Name.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ce4255",
   "metadata": {},
   "source": [
    "Aunque inicialmente se me ha ocurrido limpiar muchos falsos nombres, no estoy seguro de que deba tocar esta columna. En el cuaderno 'draft', primero unifiqué los valores con más de 4 ocurrencias (ya que no había ningún nombre real entre ellos) como 'No name'. Después hice lo mismo con todos aquellos valores que no tuvieran al menos una mayúscula. Finalmente intenté instalar spacy y NLTK con el fin de procesar el lenguaje y sacar los nombres, lo cual no conseguí. \n",
    "\n",
    "Entonces me percaté de que no iba a conseguir más nombres y que simplemente estaba quitando información de la columna sólo para sentirla ordenada, sustituyendo la mucha o poca información por un 'No name' que en principio no aporta mucho. Por ello he decidido mantenerla como está, al menos de momento, con la salvedad de rellenar los nulos como 'unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a71e4138",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Name'].fillna(value='unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26159dd",
   "metadata": {},
   "source": [
    "En cuanto a la columna 'Sex', la exploración incial devuelve que, además de los nulos, hay unos pocos valores mal informados ('M ', 'lli', '.' o 'N'). Voy a cambiarlos para que reflejen lo que corresponda en el caso de poder, y en caso contrario los convertiré en 'unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2cc0dcda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M      4982\n",
       "F       624\n",
       "M         2\n",
       "N         2\n",
       "lli       1\n",
       ".         1\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4f56c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sex'] = data['Sex'].replace({'M ': 'M', 'lli': 'M', 'N': 'M', '.': 'unknown'})\n",
    "\n",
    "data['Sex'].fillna(value='unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1c4e59a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M          4987\n",
       "F           624\n",
       "unknown     558\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4544bdf3",
   "metadata": {},
   "source": [
    "Para la columna 'Age', aun siendo consciente de que yendo caso por caso podría rellenarla mejor, he decidido aplicar lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a1d2e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17                154\n",
       "18                150\n",
       "19                141\n",
       "20                140\n",
       "15                137\n",
       "                 ... \n",
       "7      &    31      1\n",
       " 28                 1\n",
       "20?                 1\n",
       " 30                 1\n",
       "2½                  1\n",
       "Name: Age, Length: 156, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Age.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9884bce",
   "metadata": {},
   "source": [
    "Primero reemplazo los espacios vacíos con '' (nada), de forma que las edades correctas que simplemente tengan algún espacio puedan unificarse correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bff5d737",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age'] = data['Age'].str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb123ee3",
   "metadata": {},
   "source": [
    "Después reemplazo cualquier carácter no númerico por ''."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "52215714",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age'] = data['Age'].str.replace('[^0-9]', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce25be8",
   "metadata": {},
   "source": [
    "Ahora que tengo una lista de números, para todos aquellos que contengan más de dos dígitos decido aplicar una función y convertirlos en 'unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0ff5dd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age'] = data['Age'].astype(str)   # Convierto los valores de 'Age' a str para poder aplicar la función\n",
    "\n",
    "def no_age_unknown(x):\n",
    "    \n",
    "    if len(x) > 2:\n",
    "        \n",
    "        return 'unknown'\n",
    "    \n",
    "    return x\n",
    "\n",
    "data['Age'] = data['Age'].apply(no_age_unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88e9989",
   "metadata": {},
   "source": [
    "Finalmente reemplazo los espacios vacíos dejados por los antiguos valores que sólo contenían letras por 'unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e7443d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age'].replace(\"\", \"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "540fe8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown    2776\n",
       "17          154\n",
       "18          151\n",
       "20          150\n",
       "19          142\n",
       "           ... \n",
       "67            1\n",
       "84            1\n",
       "86            1\n",
       "82            1\n",
       "2             1\n",
       "Name: Age, Length: 82, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Age.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b94c23f",
   "metadata": {},
   "source": [
    "En la columna 'Injury' me pasa un poco como en la columna 'Name', que considero que unificar la información es un trabajo línea por línea, y eliminarlo no tendría sentido porque perdería información. Siempre puedo después filtrar por palabras claves como 'laceration', 'right arm' o 'bitten', si quiero buscar un tipo de lesión en concreto. Lo que sí puedo hacer es unificar los FATAL o fatal, de forma que pueda comparar mejor la columna siguiente 'Fatal'. Además, convertiré los casos no informados (NaN) en 'unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0acb36f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Injury'] = np.where(data['Injury'].str.contains('FATAL'), 'FATAL', data['Injury'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "508189c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Injury'] = np.where(data['Injury'].str.contains('atal'), 'FATAL', data['Injury'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c126fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Injury'].fillna(value='unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522cab58",
   "metadata": {},
   "source": [
    "Estudiando la siguiente columna 'Fatal', me doy cuenta de que puedo mejorar el ajuste de los valores de una columna usando los de la otra y viceversa. Aunque, para empezar, lo primero será ajustar los valores mal informados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1bea7827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N          4225\n",
       "Y          1326\n",
       "UNKNOWN      70\n",
       " N            7\n",
       "M             1\n",
       "2017          1\n",
       "N             1\n",
       "y             1\n",
       "Name: Fatal, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Fatal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5fb3124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Fatal'] = data['Fatal'].replace({' N': 'N', 'M': 'N', '2017': 'N', 'N ': 'N', 'y': 'Y'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ef78dd",
   "metadata": {},
   "source": [
    "A continuación sustituyo por 'Y' los valores en los cuales el valor correspondiente de 'Injury' sea 'FATAL' y viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ce1b1a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Fatal'] = np.where(data['Injury'] == 'FATAL', 'Y', data['Fatal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c23ef2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['Fatal'] == 'Y', 'Injury'] = 'FATAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9a64ce07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N          4230\n",
       "Y          1410\n",
       "UNKNOWN      51\n",
       "Name: Fatal, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Fatal.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d0964",
   "metadata": {},
   "source": [
    "Tras analizar las filas restantes que a pesar de los cambios contienen 'UNKNOWN', me percato de que la mayoría coinciden con un 'No details' o similar en 'Injury'. Decido convertir esos valores de ambas columnas en 'unknown', además de rellenar los valores nulos que queden del mismo modo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "155858bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Injury'] = np.where(data['Fatal'] == 'UNKNOWN', 'unknown', data['Injury'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fede1a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Fatal'].fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baa57de",
   "metadata": {},
   "source": [
    "Turno para la columna 'Time'. Exploro sus valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "124af33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12h34                                   1\n",
       "8:04 pm                                 1\n",
       "12h46                                   1\n",
       "Late morning                            1\n",
       "13h06                                   1\n",
       "13h14                                   1\n",
       "After Dusk                              1\n",
       "11h57                                   1\n",
       "Possibly same incident as 2000.08.21    1\n",
       "12h35                                   1\n",
       "17h42                                   1\n",
       "10h28                                   1\n",
       "18h25                                   1\n",
       "13h345                                  1\n",
       "                                        1\n",
       "06h47                                   1\n",
       "07h08                                   1\n",
       "                                        1\n",
       "11h115                                  1\n",
       "\"Just before 11h00\"                     1\n",
       "12h39                                   1\n",
       "13h42                                   1\n",
       "22h30                                   1\n",
       "Just before sundown                     1\n",
       "\"Evening\"                               1\n",
       "11h30                                   1\n",
       "06h10                                   1\n",
       "17h00 or 17h40                          1\n",
       "12h02                                   1\n",
       "Between 05h00 and 08h00                 1\n",
       "13h23                                   1\n",
       "13h53                                   1\n",
       "10h07                                   1\n",
       "00h30                                   1\n",
       "14h37                                   1\n",
       ">08h00                                  1\n",
       "17h11                                   1\n",
       "16h14                                   1\n",
       "12h55                                   1\n",
       "19h00-20h00                             1\n",
       "Name: Time, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Time.value_counts().tail(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93baaf19",
   "metadata": {},
   "source": [
    "Primero creo una función 'clean_time' que me permita convertir las strings que dan información en hora númerica, y doy homogeneidad a los valores sustituyendo 'h' por ':'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "00b293d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_time(x):\n",
    "    \n",
    "    x = x.replace('h', ':').replace('am', '').strip()\n",
    "    \n",
    "    if ':' not in x:\n",
    "        \n",
    "        if 'unchtime' in x:\n",
    "            return '12:00'\n",
    "        elif 'fternoon' in x:\n",
    "            return '16:00'\n",
    "        elif 'idnight' in x:\n",
    "            return '23:59'\n",
    "        elif 'orning' in x:\n",
    "            return '09:00'\n",
    "        elif 'usk' in x:\n",
    "            return '19:00'\n",
    "        elif 'vening' in x:\n",
    "            return '17:00'\n",
    "        elif 'ight' in x:\n",
    "            return '21:00'\n",
    "        elif 'idday' in x:\n",
    "            return '12:00'\n",
    "        else:\n",
    "            return 'unknown'\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "807a1344",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Time'] = data['Time'].astype(str)   # Convierto los valores de 'Age' a str para poder aplicar la función\n",
    "\n",
    "data['Time'] = data['Time'].apply(clean_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b432332a",
   "metadata": {},
   "source": [
    "Tras ello, decido limpiar el resto de carácteres no númericos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3f938e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Time'] = data['Time'].str.replace('[^0-9:]', '')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8cf684",
   "metadata": {},
   "source": [
    "Entonces creo un diccionario con los valores restantes que siguen sin el formato adecuado y los sustituyo manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5bf80eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Time'] = data['Time'].replace({':': '', '10:4511:15': '11:00', '07:0008:00': '07:30', '18:1518:30': '18:22', '06:0008:': '07:00',\n",
    "                                 '17:0017:40': '17:20', ':13:00': '13:00', '14:3015:30': '15:00', '09:0010:00': '09:30', '13:345': '13:34', '9:00': '09:00',\n",
    "                                '05:0008:00': '06:30', '17:0018:00': '17:30', '10:3013:30': '12:00', '06:0007:00': '06:30', '11:01:': '11:01',\n",
    "                                 ':03:10': '03:10', '11:0012:00': '11:30', '18:1521:30': '20:00', '10:0014:00': '12:00', '12:0014:00': '13:00', '08:0009:30': '08:45', '09:3015:30': '12:30', '12:4513:45': '13:15',\n",
    "                                '03:4504:00': '03:52', '15:0015:45': '15:22', '09:3010:00': '09:45', '16:3018:00': '17:15', '8:04': '08:04', '10:0011:00': '10:30', '2:': '02:00',\n",
    "                                '::': '', '14:0015:00': '14:30', '09:0009:30': '09:15', '06:0007:20': '06:40', ':12:00': '12:00', '11:0011:30': '11:15', '19:0020:00': '19:30',\n",
    "                                    '11:115': '11:15'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d3707c",
   "metadata": {},
   "source": [
    "Ahora sólo me falta cambiar los vacíos por 'unknown' y darle un formato adecuado a la hora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5acb75cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Time'].replace(\"\", \"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "558756e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask5 = data['Time'] != 'unknown'\n",
    "\n",
    "data.loc[mask5, 'Time'] = pd.to_datetime(data.loc[mask5, 'Time'], format='%H:%M').dt.time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614eab30",
   "metadata": {},
   "source": [
    "En la columna 'Species', hay muchísimos valores únicos, por lo que convertir el tipo en algo menos que object (por ej, categoría) parece complicado. Sí puedo convertir los NaN en 'unknown', por un lado, y por otro intentar unificar algo las especies de tiburón más repetidas, aun consciente de que algún error puede darse si dos palabras clave están en el mismo valor. Procedo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "79b9b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Species.fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "20aaced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Species'] = np.where(data['Species'].str.contains('hite'), 'White shark', data['Species'])\n",
    "\n",
    "data['Species'] = np.where(data['Species'].str.contains('iger'), 'Tiger shark', data['Species'])\n",
    "\n",
    "data['Species'] = np.where(data['Species'].str.contains('ull'), 'Bull shark', data['Species'])\n",
    "\n",
    "data['Species'] = np.where(data['Species'].str.contains('lue'), 'Blue shark', data['Species'])\n",
    "\n",
    "data['Species'] = np.where(data['Species'].str.contains('urse'), 'Nurse shark', data['Species'])\n",
    "\n",
    "data['Species'] = np.where(data['Species'].str.contains('ako'), 'Mako shark', data['Species'])\n",
    "\n",
    "data['Species'] = np.where(data['Species'].str.contains('hammer'), 'Hammerhead shark', data['Species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aca7204",
   "metadata": {},
   "source": [
    "La columna 'Source' tiene demasiados valores únicos como para considerar cambiarla en este momento, así que procedo a rellenar los valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cfc7ee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Source'].fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1d0ef",
   "metadata": {},
   "source": [
    "La columna 'pdf' parece contener el nombre del archivo adjunto en los links de 'href' y 'href formula', y además no tiene ningún valor nulo, y por tanto la voy a dejar como está"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc39384",
   "metadata": {},
   "source": [
    "Sin enmbargo, la columna 'href_formula' sí tiene un valor nulo. Lo encuentro con el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0590bd6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href_formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case_Number_1</th>\n",
       "      <th>Case_Number_2</th>\n",
       "      <th>original_order</th>\n",
       "      <th>Unnamed_22</th>\n",
       "      <th>Unnamed_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1975</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>South Australia</td>\n",
       "      <td>Coffin Bay</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>David Barrowman</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>FATAL</td>\n",
       "      <td>Y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>J. West; Adelaide Advertiser, 1/20/1975; P. Kemp, GSAF</td>\n",
       "      <td>1975.01.19-Barrowman.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_directory/1975.01.19-Barrowman.pdf</td>\n",
       "      <td>1975.01.19</td>\n",
       "      <td>1975.01.19</td>\n",
       "      <td>3059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Day  Month  Year        Type    Country             Area    Location  \\\n",
       "3214   19      1  1975  Unprovoked  AUSTRALIA  South Australia  Coffin Bay   \n",
       "\n",
       "     Activity             Name Sex Age Injury Fatal     Time  Species  \\\n",
       "3214  Surfing  David Barrowman   M  17  FATAL     Y  unknown  unknown   \n",
       "\n",
       "                                                      Source  \\\n",
       "3214  J. West; Adelaide Advertiser, 1/20/1975; P. Kemp, GSAF   \n",
       "\n",
       "                           pdf href_formula  \\\n",
       "3214  1975.01.19-Barrowman.pdf          NaN   \n",
       "\n",
       "                                                                                href  \\\n",
       "3214  http://sharkattackfile.net/spreadsheets/pdf_directory/1975.01.19-Barrowman.pdf   \n",
       "\n",
       "     Case_Number_1 Case_Number_2  original_order Unnamed_22 Unnamed_23  \n",
       "3214    1975.01.19    1975.01.19            3059        NaN        NaN  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['href_formula'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b317b6a",
   "metadata": {},
   "source": [
    "El índice es el 3214, y voy a rellenar ese nulo con los datos de la columna 'href', pues son iguales a los de 'href_formula' salvo por esta omisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e7f8ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.href_formula.iloc[3214] = data.href.iloc[3214]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "739c2312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6169 entries, 0 to 6168\n",
      "Data columns (total 24 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Day             6169 non-null   int32 \n",
      " 1   Month           6169 non-null   int32 \n",
      " 2   Year            6169 non-null   int32 \n",
      " 3   Type            6169 non-null   object\n",
      " 4   Country         6169 non-null   object\n",
      " 5   Area            6169 non-null   object\n",
      " 6   Location        6169 non-null   object\n",
      " 7   Activity        6169 non-null   object\n",
      " 8   Name            6169 non-null   object\n",
      " 9   Sex             6169 non-null   object\n",
      " 10  Age             6169 non-null   object\n",
      " 11  Injury          6169 non-null   object\n",
      " 12  Fatal           6169 non-null   object\n",
      " 13  Time            6169 non-null   object\n",
      " 14  Species         6169 non-null   object\n",
      " 15  Source          6169 non-null   object\n",
      " 16  pdf             6169 non-null   object\n",
      " 17  href_formula    6169 non-null   object\n",
      " 18  href            6169 non-null   object\n",
      " 19  Case_Number_1   6169 non-null   object\n",
      " 20  Case_Number_2   6169 non-null   object\n",
      " 21  original_order  6169 non-null   int32 \n",
      " 22  Unnamed_22      1 non-null      object\n",
      " 23  Unnamed_23      2 non-null      object\n",
      "dtypes: int32(4), object(20)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0154f0fa",
   "metadata": {},
   "source": [
    "Las columnas 'Case_Number_1' y 'Case_Number_2' contienen una vez más las fechas que ya hemos adecuado en las primeras columnas. A la columna 'Case_Number_1' la voy a convertir en simplemente 'Case_Number', donde voy a dejar guardado el número de caso en orden descendente, ya que no coincidirá con 'original_order', la cual he decidido mantener como está para saber el orden original del caso. \n",
    "\n",
    "A la columna 'Case_Number_2' la voy a convertir en una columna de fecha llamada 'Date' con los valores de 'Day', 'Month' y 'Year' sumados.\n",
    "\n",
    "Finalmente y para no volver a usar el .rename, aprovecho y renombro las dos columnas finales para avisar de lo que son y prevenir su uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b0d7e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'Case_Number_1': 'Case_Number', 'Case_Number_2': 'Date',\n",
    "                     'Unnamed_22': 'no_data_1', 'Unnamed_23': 'no_data_2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "64140b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Case_Number'] = [len(data) - i for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d973dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] = data['Year'].astype(str) + '-' + data['Month'].astype(str) + '-' + data['Day'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8284321d",
   "metadata": {},
   "source": [
    "Aunque ahora pretendía cambiar el tipo de la columna a tipo fecha, al hacerlo no me permite convertir las últimas filas, y según he investigado podría ser porque son demasiado lejanas en el tiempo. Puedo forzar a hacerlo al código usando un errors=coerce, pero entonces esos valores son NaT. Así que, de momento y hasta que haga el análisis de tipos para optimizar DataFrame, no cambio el formato a fecha."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759fd018",
   "metadata": {},
   "source": [
    "Como especificado anteriormente, la columna 'original_order' la dejo como está, así que sólo faltaría ajustar los valores de las últimas dos columnas. He decidido que sean 0 para que pesen menos y, al comprobar el número de 'unknown's por fila, no computen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4b2eabb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.no_data_1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f9d922f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.no_data_2 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd4caad",
   "metadata": {},
   "source": [
    "Para terminar quiero comprobar si alguna fila tiene más del 50% de 'unknown's sobre 22 columnas, ya que las últimas dos no conviene tenerlas en cuenta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "77bf8837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((data == 'unknown').sum(axis=1) > 11).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c19a0d0",
   "metadata": {},
   "source": [
    "Ninguna fila tiene más de la mitad de 'unknown', por lo que no elimino ninguna y el DataFrame se queda como está. Ahora solo falta intentar ajustar los tipos de dato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9ee52ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in data.select_dtypes('object'):\n",
    "    \n",
    "    data[c]=data[c].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bcdefdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6169 entries, 0 to 6168\n",
      "Data columns (total 24 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   Day             6169 non-null   int32   \n",
      " 1   Month           6169 non-null   int32   \n",
      " 2   Year            6169 non-null   int32   \n",
      " 3   Type            6169 non-null   category\n",
      " 4   Country         6169 non-null   category\n",
      " 5   Area            6169 non-null   category\n",
      " 6   Location        6169 non-null   category\n",
      " 7   Activity        6169 non-null   category\n",
      " 8   Name            6169 non-null   category\n",
      " 9   Sex             6169 non-null   category\n",
      " 10  Age             6169 non-null   category\n",
      " 11  Injury          6169 non-null   category\n",
      " 12  Fatal           6169 non-null   category\n",
      " 13  Time            6169 non-null   category\n",
      " 14  Species         6169 non-null   category\n",
      " 15  Source          6169 non-null   category\n",
      " 16  pdf             6169 non-null   category\n",
      " 17  href_formula    6169 non-null   category\n",
      " 18  href            6169 non-null   category\n",
      " 19  Case_Number     6169 non-null   int64   \n",
      " 20  Date            6169 non-null   category\n",
      " 21  original_order  6169 non-null   int32   \n",
      " 22  no_data_1       6169 non-null   int64   \n",
      " 23  no_data_2       6169 non-null   int64   \n",
      "dtypes: category(17), int32(4), int64(3)\n",
      "memory usage: 5.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "567fd5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6169 entries, 0 to 6168\n",
      "Data columns (total 24 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   Day             6169 non-null   int8    \n",
      " 1   Month           6169 non-null   int8    \n",
      " 2   Year            6169 non-null   int16   \n",
      " 3   Type            6169 non-null   category\n",
      " 4   Country         6169 non-null   category\n",
      " 5   Area            6169 non-null   category\n",
      " 6   Location        6169 non-null   category\n",
      " 7   Activity        6169 non-null   category\n",
      " 8   Name            6169 non-null   category\n",
      " 9   Sex             6169 non-null   category\n",
      " 10  Age             6169 non-null   category\n",
      " 11  Injury          6169 non-null   category\n",
      " 12  Fatal           6169 non-null   category\n",
      " 13  Time            6169 non-null   category\n",
      " 14  Species         6169 non-null   category\n",
      " 15  Source          6169 non-null   category\n",
      " 16  pdf             6169 non-null   category\n",
      " 17  href_formula    6169 non-null   category\n",
      " 18  href            6169 non-null   category\n",
      " 19  Case_Number     6169 non-null   int16   \n",
      " 20  Date            6169 non-null   category\n",
      " 21  original_order  6169 non-null   int16   \n",
      " 22  no_data_1       6169 non-null   int8    \n",
      " 23  no_data_2       6169 non-null   int8    \n",
      "dtypes: category(17), int16(3), int8(4)\n",
      "memory usage: 5.3 MB\n"
     ]
    }
   ],
   "source": [
    "for c in data.select_dtypes('integer'):\n",
    "    \n",
    "    data[c]=pd.to_numeric(data[c], downcast='integer')\n",
    "    \n",
    "data.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a601e1d4",
   "metadata": {},
   "source": [
    "Para finalizar, imprimo el DataFrame final y lo exporto a carpeta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a95edb7",
   "metadata": {},
   "source": [
    "# DataFrame Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5f0f6dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6169, 24), (25723, 24))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, data_ori_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "274b773f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Injury</th>\n",
       "      <th>Fatal</th>\n",
       "      <th>Time</th>\n",
       "      <th>Species</th>\n",
       "      <th>Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href_formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case_Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>original_order</th>\n",
       "      <th>no_data_1</th>\n",
       "      <th>no_data_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>2018</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>No injury to occupant, outrigger canoe and paddle damaged</td>\n",
       "      <td>N</td>\n",
       "      <td>18:00:00</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_directory/2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_directory/2018.06.25-Wolfe.pdf</td>\n",
       "      <td>6169</td>\n",
       "      <td>2018-6-25</td>\n",
       "      <td>6303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Little Congwong Beach, La Perouse</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Anna Shurapey</td>\n",
       "      <td>F</td>\n",
       "      <td>55</td>\n",
       "      <td>Laceratons to right leg &amp; foot</td>\n",
       "      <td>N</td>\n",
       "      <td>19:00:00</td>\n",
       "      <td>White shark</td>\n",
       "      <td>B. Myatt, GSAF</td>\n",
       "      <td>2018.02.23-Shurapey.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_directory/2018.02.23-Shurapey.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_directory/2018.02.23-Shurapey.pdf</td>\n",
       "      <td>6168</td>\n",
       "      <td>2018-2-23</td>\n",
       "      <td>6263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Western Australia</td>\n",
       "      <td>Cobblestones, Margaret River Area</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Alejandro Travaglini</td>\n",
       "      <td>M</td>\n",
       "      <td>37</td>\n",
       "      <td>Lacerations to legs</td>\n",
       "      <td>N</td>\n",
       "      <td>08:00:00</td>\n",
       "      <td>unknown</td>\n",
       "      <td>B.Myatt, GSAF</td>\n",
       "      <td>2018.04.15.a-Travaglini.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_directory/2018.04.15.a-Travaglini.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_directory/2018.04.15.a-Travaglini.pdf</td>\n",
       "      <td>6167</td>\n",
       "      <td>2018-4-15</td>\n",
       "      <td>6274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>BAHAMAS</td>\n",
       "      <td>New Providence</td>\n",
       "      <td>Nirvana Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Bruce Rowan</td>\n",
       "      <td>M</td>\n",
       "      <td>unknown</td>\n",
       "      <td>No Injury. Shark swam away with the surf board</td>\n",
       "      <td>N</td>\n",
       "      <td>09:30:00</td>\n",
       "      <td>Tiger shark</td>\n",
       "      <td>Tribune242,</td>\n",
       "      <td>2018.04.14-Rowan.pff</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_directory/2018.04.14-Rowan.pff</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_directory/2018.04.14-Rowan.pff</td>\n",
       "      <td>6166</td>\n",
       "      <td>2018-4-14</td>\n",
       "      <td>6273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>BRAZIL</td>\n",
       "      <td>Alagoas</td>\n",
       "      <td>Praia de Sauaçuhy, Maceió</td>\n",
       "      <td>Fishing</td>\n",
       "      <td>Josias Paz</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>Injury to ankle from marine animal trapped in weir PROVOKED INCIDENT.</td>\n",
       "      <td>N</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Shark involvement not confirmed</td>\n",
       "      <td>K. McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.04.10.R-Paz.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_directory/2018.04.10.R-Paz.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_directory/2018.04.10.R-Paz.pdf</td>\n",
       "      <td>6165</td>\n",
       "      <td>2018-1-10</td>\n",
       "      <td>6272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Day  Month  Year        Type    Country               Area  \\\n",
       "0   25      6  2018     Boating        USA         California   \n",
       "1   23      2  2018  Unprovoked  AUSTRALIA    New South Wales   \n",
       "2   15      4  2018  Unprovoked  AUSTRALIA  Western Australia   \n",
       "3   14      4  2018  Unprovoked    BAHAMAS     New Providence   \n",
       "4   10      1  2018     Invalid     BRAZIL            Alagoas   \n",
       "\n",
       "                             Location  Activity                  Name Sex  \\\n",
       "0         Oceanside, San Diego County   unknown           Julie Wolfe   F   \n",
       "1  Little Congwong Beach, La Perouse   Swimming        Anna Shurapey    F   \n",
       "2   Cobblestones, Margaret River Area   Surfing  Alejandro Travaglini   M   \n",
       "3                       Nirvana Beach   Surfing           Bruce Rowan   M   \n",
       "4           Praia de Sauaçuhy, Maceió   Fishing            Josias Paz   M   \n",
       "\n",
       "       Age  \\\n",
       "0       57   \n",
       "1       55   \n",
       "2       37   \n",
       "3  unknown   \n",
       "4       56   \n",
       "\n",
       "                                                                   Injury  \\\n",
       "0               No injury to occupant, outrigger canoe and paddle damaged   \n",
       "1                                          Laceratons to right leg & foot   \n",
       "2                                                     Lacerations to legs   \n",
       "3                          No Injury. Shark swam away with the surf board   \n",
       "4  Injury to ankle from marine animal trapped in weir PROVOKED INCIDENT.    \n",
       "\n",
       "  Fatal      Time                          Species  \\\n",
       "0     N  18:00:00                      White shark   \n",
       "1     N  19:00:00                      White shark   \n",
       "2     N  08:00:00                          unknown   \n",
       "3     N  09:30:00                      Tiger shark   \n",
       "4     N   unknown  Shark involvement not confirmed   \n",
       "\n",
       "                            Source                          pdf  \\\n",
       "0                 R. Collier, GSAF         2018.06.25-Wolfe.pdf   \n",
       "1                   B. Myatt, GSAF      2018.02.23-Shurapey.pdf   \n",
       "2                    B.Myatt, GSAF  2018.04.15.a-Travaglini.pdf   \n",
       "3                      Tribune242,         2018.04.14-Rowan.pff   \n",
       "4  K. McMurray, TrackingSharks.com         2018.04.10.R-Paz.pdf   \n",
       "\n",
       "                                                                        href_formula  \\\n",
       "0         http://sharkattackfile.net/spreadsheets/pdf_directory/2018.06.25-Wolfe.pdf   \n",
       "1      http://sharkattackfile.net/spreadsheets/pdf_directory/2018.02.23-Shurapey.pdf   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_directory/2018.04.15.a-Travaglini.pdf   \n",
       "3         http://sharkattackfile.net/spreadsheets/pdf_directory/2018.04.14-Rowan.pff   \n",
       "4         http://sharkattackfile.net/spreadsheets/pdf_directory/2018.04.10.R-Paz.pdf   \n",
       "\n",
       "                                                                                href  \\\n",
       "0         http://sharkattackfile.net/spreadsheets/pdf_directory/2018.06.25-Wolfe.pdf   \n",
       "1      http://sharkattackfile.net/spreadsheets/pdf_directory/2018.02.23-Shurapey.pdf   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_directory/2018.04.15.a-Travaglini.pdf   \n",
       "3         http://sharkattackfile.net/spreadsheets/pdf_directory/2018.04.14-Rowan.pff   \n",
       "4         http://sharkattackfile.net/spreadsheets/pdf_directory/2018.04.10.R-Paz.pdf   \n",
       "\n",
       "   Case_Number       Date  original_order  no_data_1  no_data_2  \n",
       "0         6169  2018-6-25            6303          0          0  \n",
       "1         6168  2018-2-23            6263          0          0  \n",
       "2         6167  2018-4-15            6274          0          0  \n",
       "3         6166  2018-4-14            6273          0          0  \n",
       "4         6165  2018-1-10            6272          0          0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ffd3ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('clean_sharks.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ebf471354e23f250901b2e36c13a3fc6a7e10eee4298215e1df0bbbb17e89b7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
